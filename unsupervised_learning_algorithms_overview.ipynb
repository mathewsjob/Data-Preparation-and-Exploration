{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c214b04",
   "metadata": {},
   "source": [
    "# Unsupervised Learning Algorithms Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29411fdf",
   "metadata": {},
   "source": [
    "## 1. Clustering Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17174d96",
   "metadata": {},
   "source": [
    "\n",
    "### 1.1 K-Means Clustering\n",
    "- **Description**: Partitions data into K clusters by minimizing the variance within each cluster.\n",
    "- **Use Case**: Customer segmentation.\n",
    "\n",
    "### 1.2 Hierarchical Clustering\n",
    "- **Description**: Creates a tree-like structure of clusters (dendrogram) through agglomerative (bottom-up) or divisive (top-down) approaches.\n",
    "- **Use Case**: Gene expression analysis.\n",
    "\n",
    "### 1.3 DBSCAN (Density-Based Spatial Clustering of Applications with Noise)\n",
    "- **Description**: Groups points that are closely packed together while marking points in low-density regions as outliers.\n",
    "- **Use Case**: Identifying clusters of varying density.\n",
    "\n",
    "### 1.4 Gaussian Mixture Models (GMM)\n",
    "- **Description**: Assumes data is generated from a mixture of several Gaussian distributions, providing a probabilistic approach to clustering.\n",
    "- **Use Case**: Image segmentation.\n",
    "\n",
    "### 1.5 Mean Shift Clustering\n",
    "- **Description**: A non-parametric clustering technique that shifts data points towards the region of maximum density in feature space.\n",
    "- **Use Case**: Object tracking in computer vision.\n",
    "\n",
    "### 1.6 Affinity Propagation\n",
    "- **Description**: Identifies exemplars among data points and forms clusters based on message passing.\n",
    "- **Use Case**: Document clustering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f7fdf3",
   "metadata": {},
   "source": [
    "## 2. Association Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02df8ee",
   "metadata": {},
   "source": [
    "\n",
    "### 2.1 Apriori Algorithm\n",
    "- **Description**: A classic algorithm for mining frequent itemsets and generating association rules based on support and confidence.\n",
    "- **Use Case**: Market basket analysis.\n",
    "\n",
    "### 2.2 FP-Growth (Frequent Pattern Growth)\n",
    "- **Description**: An improvement over Apriori that uses a tree structure to store frequent itemsets without candidate generation.\n",
    "- **Use Case**: Recommendation systems.\n",
    "\n",
    "### 2.3 ECLAT (Equivalence Class Transformation)\n",
    "- **Description**: A method for finding frequent itemsets that uses a depth-first search strategy to count itemsets.\n",
    "- **Use Case**: Market basket analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1099db3",
   "metadata": {},
   "source": [
    "## 3. Dimensionality Reduction Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964281b6",
   "metadata": {},
   "source": [
    "\n",
    "### 3.1 Principal Component Analysis (PCA)\n",
    "- **Description**: A linear technique that transforms the data into fewer dimensions by projecting it onto principal components.\n",
    "- **Use Case**: Data visualization and noise reduction.\n",
    "\n",
    "### 3.2 t-SNE (t-distributed Stochastic Neighbor Embedding)\n",
    "- **Description**: A non-linear technique that visualizes high-dimensional data by reducing it to two or three dimensions while preserving local structures.\n",
    "- **Use Case**: Visualizing clusters in high-dimensional data.\n",
    "\n",
    "### 3.3 UMAP (Uniform Manifold Approximation and Projection)\n",
    "- **Description**: A technique that preserves more of the global structure of data while reducing dimensionality.\n",
    "- **Use Case**: Visualizing complex datasets.\n",
    "\n",
    "### 3.4 Autoencoders\n",
    "- **Description**: Neural networks designed to learn efficient representations (encoding) of the input data.\n",
    "- **Use Case**: Image compression and denoising.\n",
    "\n",
    "### 3.5 Independent Component Analysis (ICA)\n",
    "- **Description**: A computational technique for separating a multivariate signal into additive independent components.\n",
    "- **Use Case**: Signal processing and blind source separation.\n",
    "\n",
    "### 3.6 Kernel PCA\n",
    "- **Description**: An extension of PCA that uses kernel methods to capture non-linear relationships.\n",
    "- **Use Case**: Image recognition tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6834c4c7",
   "metadata": {},
   "source": [
    "## 4. Anomaly Detection Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff64c0ed",
   "metadata": {},
   "source": [
    "\n",
    "### 4.1 Isolation Forest\n",
    "- **Description**: Identifies anomalies by isolating observations in a tree structure; anomalies are isolated faster than normal points.\n",
    "- **Use Case**: Fraud detection.\n",
    "\n",
    "### 4.2 One-Class SVM\n",
    "- **Description**: A variant of SVM used for anomaly detection by learning a decision boundary around normal data.\n",
    "- **Use Case**: Network intrusion detection.\n",
    "\n",
    "### 4.3 Local Outlier Factor (LOF)\n",
    "- **Description**: Measures the local density deviation of a given data point with respect to its neighbors to identify outliers.\n",
    "- **Use Case**: Detecting anomalies in sensor data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90deb57a",
   "metadata": {},
   "source": [
    "## 5. Self-Organizing Maps (SOM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416959dc",
   "metadata": {},
   "source": [
    "\n",
    "- **Description**: A type of artificial neural network that is trained using unsupervised learning to produce a low-dimensional representation of the input space.\n",
    "- **Use Case**: Visualizing high-dimensional data.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
